---
comments: true
---

# 第八章 - 假设检验

## 假设检验的基本思想

### 问题的提出

统计假设简称为假设，通常用字母 $H$ 表示。一般我们同时提出两个完全相反的假设，习惯上把其中的一个称作**原假设** (null hypothesis) 或**零假设**，用 $H_{0}$ 表示；把另一个假设称作**备择假设** (alternative hypothesis) 或**对立假设**，用 $H_{1}$ 表示。一般地，在有关参数的假设检验中，备择假设是我们根据样本资料想得到支持的假设。

关于总体参数 $\theta$ 的假设，有三种情况：

1. $H_{0}: \theta \geq \theta_{0}, H_{1}: \theta < \theta_{0}$
2. $H_{0}: \theta \leq \theta_{0}, H_{1}: \theta > \theta_{0}$
3. $H_{0}: \theta = \theta_{0}, H_{1}: \theta \neq \theta_{0}$

其中 $\theta_{0}$ 是已知常数。以上三种情况中，前两种假设的检验称作**单侧检验** (one-sided test)；第三种假设的检验称作**双侧检验** (two-sided test)。

此外，单侧检验还有下列两种形式：

1. $H_{0}: \theta = \theta_{0}, H_{1}: \theta < \theta_{0}$
2. $H_{0}: \theta = \theta_{0}, H_{1}: \theta > \theta_{0}$

### 检验统计量和拒绝域

一般地，在假设检验问题中，若寻找到某个统计量，其取值大小和原假设 $H_{0}$ 是否成立有密切联系，我们称之为该假设检验问题的**检验统计量** (test statistic)，对应于拒绝原假设 $H_{0}$ 的样本值范围称作**拒绝域** (rejection region)，记作 $W$。拒绝域 $W$ 的补集 $\overline{W}$ 称作**接受域** (acceptance region)。如果样本落入拒绝域 $W$ 内，就拒绝原假设 $H_{0}$；如果样本未落入拒绝域 $W$ 内，就接受原假设 $H_{0}$。

因此，对于一个假设检验问题，给出一个检验规则，相当于在样本空间中划分出一个子集作为检验的拒绝域；反之，给出一个拒绝域也就给出了一个检验规则。故如何选取检验的拒绝域就成为假设检验的一个关键问题。

### 两类错误

在给出具体的假设检验方法之前，我们需要先讨论假设检验问题中可能出现的两类错误。

根据样本推断总体，由于抽样的随机性，所做的结论不能保证绝对不犯错误，而只能以较大的概率保证其正确性。在假设检验推断中可能出现下列四种情形：

1. 拒绝了一个错误的原假设
2. 接受了一个真实的原假设
3. 拒绝了一个真实的原假设
4. 接受了一个错误的原假设

其中前两种情形是正确的。第三种情形称作**第 I 类错误** (type I error)，也称作**弃真错误**；第四种情形称作**第 II 类错误** (type II error)，也称作**存伪错误**。通常，用 $\alpha$ 表示犯第 I 类错误的概率，用 $\beta$ 表示犯第 II 类错误的概率。具体地，有

$$\begin{aligned}
    \alpha & = P(\text{第 I 类错误}) = P\{ \text{拒绝 } H_{0} | H_{0} \text{ 是真实的} \} \\
    \beta & = P(\text{第 II 类错误}) = P\{ \text{接受 } H_{0} | H_{0} \text{ 是错误的} \}
\end{aligned}$$

一般来说，当样本容量固定时，犯这两类错误的概率是相互制约的，使其中一者减小往往伴随着另一者增大。若要同时使得犯两类错误的概率都减小，就必须增大样本容量。

鉴于上述情况，奈曼和皮尔逊提出：首先控制犯第 I 类错误的概率，即选定一个常数 $\alpha \in (0, 1)$，要求犯第 I 类错误的概率不超过 $\alpha$；然后在满足这个约束条件的检验中，再寻找使得犯第 II 类错误的概率尽量小的检验。这就是假设检验理论中的**奈曼-皮尔逊原则** (Neyman-Pearson lemma)，其中的常数 $\alpha$ 称作**显著性水平** (significance level)。

### $P$-值与统计显著性

在原假设和备择假设中，我们只考虑检验统计量是否落在拒绝域内。但直观上，检验统计量与临界值的距离也会影响我们拒绝或接受原假设的把握。例如当检验统计量落在拒绝域内时，其值离临界值越远，我们拒绝原假设的理由就越充分，检验越显著。

我们采用 $P$-值来衡量这一现象，当原假设 $H_{0}$ 为真时，检验统计量取比观察到的结果更为极端的数值的概率称作 $P$-值。在实际运用中，通过计算 $P$-值来衡量拒绝 $H_{0}$ 的理由是否充分。$P$-值较小说明观察到的结果在一次实验中发生的可能性较小，$P$-值越小，拒绝 $H_{0}$ 的理由越充分；$P$-值较大说明观察到的结果在一次实验中发生的可能性较大，所以没有足够的理由拒绝 $H_{0}$。

当假设检验的显著性水平为 $\alpha$ 时，若 $P$-值小于等于 $\alpha$，则拒绝原假设，此时我们称检验结果在显著性水平 $\alpha$ 下是**统计显著** (statistically significant) 的。

可以说 $P$-值提供了比显著性水平 $\alpha$ 更多的信息，根据 $P$-值，我们可以判定在任何给定的显著性水平下检验结果是否显著。

### 处理假设检验问题的基本步骤

一般的假设检验问题我们可按下列步骤进行：

1. 根据实际问题提出原假设和备择假设；
2. 提出检验统计量和拒绝域的形式；
3. 根据奈曼-皮尔逊原则和给定的显著性水平 $\alpha$，求出拒绝域 $W$ 中的临界值；
4. 根据实际样本值作出判断。

如果从 $P$-值出发考察，步骤也可如下进行：

1. 根据实际问题提出原假设和备择假设；
2. 提出检验统计量和拒绝域的形式；
3. 计算检验统计量的观测值和 $P$-值；
4. 根据给定的显著性水平 $\alpha$ 作出判断。

## 单个正态总体参数的假设检验

设正态总体 $X \sim N(\mu, \sigma^{2})$，$X_{1}, X_{2}, \cdots, X_{n}$ 是来自该总体的样本，记

$$\bar{X} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}, S^{2} = \frac{1}{n - 1} \sum_{i = 1}^{n} (X_{i} - \bar{X})^{2}$$

### 有关参数 $\mu$ 的假设检验

#### $\sigma^{2}$ 已知

先考虑双侧假设问题

$$H_{0}: \mu = \mu_{0}, H_{1}: \mu \neq \mu_{0}$$

其中 $\mu_{0}$ 是已知的常量。此时我们取检验统计量

$$Z = \frac{\bar{X} - \mu_{0}}{\frac{\sigma}{\sqrt{n}}}$$

当原假设 $H_{0}$ 成立，即 $\mu = \mu_{0}$ 时，$Z \sim N(0, 1)$，根据奈曼-皮尔逊原则，在给定的显著性水平 $\alpha$ 下，检验的拒绝域为

$$W = \left\{ |Z| = \left| \frac{\bar{X} - \mu_{0}}{\frac{\sigma}{\sqrt{n}}} \right| \geq z_{\frac{\alpha}{2}} \right\}$$

对给定样本值 $x_{1}, x_{2}, \cdots, x_{n}$，检验统计量 $Z$ 的取值 $z_{0} = \frac{\bar{x} - \mu_{0}}{\frac{\sigma}{\sqrt{n}}}$。当 $|z_{0}| \geq z_{\frac{\alpha}{2}}$ 时，就作出拒绝原假设的判断，即认为根据当前样本资料，我们有 $1 - \alpha$ 的把握认为 $\mu \neq \mu_{0}$；否则不拒绝原假设。

我们也可以通过计算 $P$-值来做出判断，其中

$$P\text{-值} = P_{H_{0}} \{ |Z| \geq |z_{0}| \} = 2 P_{H_{0}} \{ Z \geq |z_{0}| \} = 2(1 - \Phi(|z_{0}|))$$

当 $P$-值小于等于给定的显著性水平时，拒绝原假设，否则不能拒绝原假设。

对于左侧假设问题

$$H_{0}: \mu \geq \mu_{0}, H_{1}: \mu < \mu_{0}$$

检验统计量仍为

$$Z = \frac{\bar{X} - \mu_{0}}{\frac{\sigma}{\sqrt{n}}}$$

当原假设 $H_{0}$ 成立，即 $\mu \geq \mu_{0}$ 时，$Z$ 取值偏大，检验的拒绝域为

$$W = \left\{ Z = \frac{\bar{X} - \mu_{0}}{\frac{\sigma}{\sqrt{n}}} \leq c \right\}$$

其中临界值 $c$ 满足奈曼-皮尔逊原则。首先我们来计算犯第 I 类错误的概率：

$$\alpha(\mu, c) = P\{ \text{拒绝 } H_{0} | H_{0} \text{ 是真实的} \} = P \left\{ \frac{\bar{X} - \mu_{0}}{\frac{\sigma}{\sqrt{n}}} \leq c | \mu \geq \mu_{0} \right\}$$

注意到此时 $Z$ 不服从标准正态分布，而是

$$Z \sim N \left( \frac{\mu - \mu_{0}}{\frac{\sigma}{\sqrt{n}}}, 1 \right), \mu \geq \mu_{0}$$

因此

$$\alpha(\mu, c) = \Phi \left( c - \frac{\mu - \mu_{0}}{\frac{\sigma}{\sqrt{n}}} \right), \mu \geq \mu_{0}$$

> 如果假设为 $H_{0}: \mu = \mu_{0}, H_{1}: \mu < \mu_{0}$，那么犯第 I 类错误的概率为 $\alpha(\mu_{0}, c)$。从这一点来看，两个假设检验是有区别的。

显然，$\alpha(\mu, c)$ 关于 $\mu$ 是严格减函数，为使犯第 I 类错误的概率不超过给定的显著性水平 $\alpha$，需满足

$$\sup_{\mu \geq \mu_{0}} \alpha(\mu, c) = \alpha(\mu_{0}, c) = \Phi(c) \leq \alpha$$

又根据奈曼-皮尔逊原则，当上式中等号成立时，犯第 II 类错误的概率最小。因此，应取 $c = z_{1 - \alpha} = -z_{\alpha}$，故左侧假设检验问题的拒绝域为

$$W = \left\{ Z = \frac{\bar{X} - \mu_{0}}{\frac{\sigma}{\sqrt{n}}} \leq -z_{\alpha} \right\}$$

我们也可以通过计算 $P$-值来做出判断，其中

$$P\text{-值} = \sup_{\mu \geq \mu_{0}} P \{ Z \leq z_{0} \} = P \{ Z \leq z_{0} | \mu = \mu_{0} \} = \Phi(z_{0})$$

当 $P$-值小于等于给定的显著性水平 $\alpha$ 时，拒绝原假设 $H_{0}$，否则不能拒绝原假设 $H_{0}$。

类似地，对于右侧假设问题

$$H_{0}: \mu \leq \mu_{0}, H_{1}: \mu > \mu_{0}$$

检验的拒绝域为

$$W = \left\{ Z = \frac{\bar{X} - \mu_{0}}{\frac{\sigma}{\sqrt{n}}} \geq z_{\alpha} \right\}$$

$P$-值为

$$P\text{-值} = \sup_{\mu \leq \mu_{0}} P \{ Z \geq z_{0} \} = P \{ Z \geq z_{0} | \mu = \mu_{0} \} = 1 - \Phi(z_{0})$$

上述检验称作 $Z$ 检验。

#### $\sigma^{2}$ 未知

当参数 $\sigma^{2}$ 未知时，我们不能采用 $Z$ 检验，而是需要用样本方差 $S^{2}$ 来代替 $\sigma^{2}$，从而得到检验统计量

$$T = \frac{\bar{X} - \mu_{0}}{\frac{S}{\sqrt{n}}}$$

根据 $t$ 分布的性质，我们知道

$$T = \frac{\bar{X} - \mu_{0}}{\frac{S}{\sqrt{n}}} \sim t(n - 1)$$

于是当给定样本值 $x_{1}, x_{2}, \cdots, x_{n}$ 时，检验统计量 $t_{0} = \frac{\bar{x} - \mu_{0}}{\frac{S}{\sqrt{n}}}$。根据 $t$ 分布，我们可计算出相应的拒绝域和 $P$-值。

双侧假设问题

$$H_{0}: \mu = \mu_{0}, H_{1}: \mu \neq \mu_{0}$$

拒绝域为

$$W = \left\{ |T| = \left| \frac{\bar{X} - \mu_{0}}{\frac{S}{\sqrt{n}}} \right| \geq t_{\frac{\alpha}{2}} (n - 1) \right\}$$

$P$-值为

$$P\text{-值} = 2 P \{ t(n - 1) \geq |t_{0}| \}$$

左侧假设问题

$$H_{0}: \mu \geq \mu_{0}, H_{1}: \mu < \mu_{0}$$

拒绝域为

$$W = \left\{ T = \frac{\bar{X} - \mu_{0}}{\frac{S}{\sqrt{n}}} \leq -t_{\alpha} (n - 1) \right\}$$

$P$-值为

$$P\text{-值} = \sup_{\mu \geq \mu_{0}} P \{ T \leq t_{0} \} = P \{ t(n - 1) \leq t_{0} \}$$

右侧假设问题

$$H_{0}: \mu \leq \mu_{0}, H_{1}: \mu > \mu_{0}$$

拒绝域为

$$W = \left\{ T = \frac{\bar{X} - \mu_{0}}{\frac{S}{\sqrt{n}}} \geq t_{\alpha} (n - 1) \right\}$$

$P$-值为

$$P\text{-值} = \sup_{\mu \leq \mu_{0}} P \{ T \leq t_{0} \} = P \{ t(n - 1) \geq t_{0} \}$$

上述检验称作 $t$ 检验。

### 成对数据的 $t$ 检验

对于成对数据样本 $(X_{1}, Y_{1}), (X_{2}, Y_{2}), \cdots, (X_{n}, Y_{n})$，$X_{i}$ 和 $Y_{i}$ 一般不独立，且 $X_{1}, X_{2}, \cdots, X_{n}$ 不能看作是来自同一个正态总体的样本，$Y_{1}, Y_{2}, \cdots, Y_{n}$ 也不能看作是来自同一个正态总体的样本。

此时，我们一般考察差值 $D_{i} = X_{i} - Y_{i}, i = 1, 2, \cdots, n$。我们可以将 $D_{1}, D_{2}, \cdots, D_{n}$ 看作是来自同一个正态总体 $N(\mu_{D}, \sigma_{D}^{2})$ 的样本。所以，对成对数据差的假设检验可以转化为对单个正态总体均值 $\mu_{D}$ 的假设检验。

### 有关参数 $\sigma^{2}$ 的假设检验

我们不妨设参数 $\mu$ 是未知的，其假设问题包括

- 双侧假设：$H_{0}: \sigma^{2} = \sigma_{0}^{2}, H_{1}: \sigma^{2} \neq \sigma_{0}^{2}$
- 左侧假设：$H_{0}: \sigma^{2} \geq \sigma_{0}^{2}, H_{1}: \sigma^{2} < \sigma_{0}^{2}$
- 右侧假设：$H_{0}: \sigma^{2} \leq \sigma_{0}^{2}, H_{1}: \sigma^{2} > \sigma_{0}^{2}$

其中 $\sigma_{0}^{2}$ 是已知的常量。此时 $\sigma^{2}$ 的无偏估计量

$$S^{2} = \frac{1}{n - 1} \sum_{i = 1}^{n} (X_{i} - \bar{X})^{2}$$

且 $\frac{(n - 1) S^{2}}{\sigma^{2}} \sim \chi^{2}(n - 1)$。因此，可取检验统计量为

$$\chi^{2} = \frac{(n - 1) S^{2}}{\sigma_{0}^{2}}$$

当 $\sigma^{2} = \sigma_{0}^{2}$ 时，检验统计量 $\chi^{2}$ 的分布是已知的，$\chi^{2} \sim \chi^{2} (n - 1)$。在给定显著性水平 $\alpha$ 时，有检验拒绝域：

- 双侧检验：$W = \{ \chi^{2} \geq \chi_{\frac{\alpha}{2}}^{2} (n - 1) \}$ 或 $W = \{ \chi^{2} \leq \chi_{1 - \frac{\alpha}{2}}^{2} (n - 1) \}$
- 左侧检验：$W = \{ \chi^{2} \leq \chi_{1 - \alpha}^{2} (n - 1) \}$
- 右侧检验：$W = \{ \chi^{2} \geq \chi_{\alpha}^{2} (n - 1) \}$

为了计算 $P$-值，将样本值代入后得到检验统计量的值记作 $\chi_{0}^{2}$，即 $\chi_{0}^{2} = \frac{(n - 1) s^{2}}{\sigma_{0}^{2}}$，记

$$p_{0} = P_{\sigma^{2} = \sigma_{0}^{2}} \left\{ \frac{(n - 1) S^{2}}{\sigma_{0}^{2}} \leq \frac{(n - 1) s^{2}}{\sigma_{0}^{2}} \right\} = P \{ \chi^{2} (n - 1) \leq \chi_{0}^{2} \}$$

- 双侧检验：$P\text{-值} = 2 \min \{ p_{0}, 1 - p_{0} \}$
- 左侧检验：$P\text{-值} = p_{0}$
- 右侧检验：$P\text{-值} = 1 - p_{0}$

我们称上述检验为 $\chi^{2}$ 检验。
