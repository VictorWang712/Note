---
comments: true
---

# [arXiv] Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores

???+ info

    - Author: Yuvraj Virk, Premkumar Devanbu, Toufique Ahmed
    - arXiv: [2404.19318](https://arxiv.org/abs/2404.19318)

## 论文概述

该研究探讨了**大语言模型（LLM, Large Language Model）在生成代码摘要（Code Summarization）时的可靠性问题**。尽管 LLM 生成的摘要可以提高代码理解效率，但它们的质量存在较大变动，可能过长、无关或偏离人类编写的摘要。因此，该研究提出了一种**校准置信度评分（Calibrated Confidence Score）**的方法，以衡量 LLM 生成摘要的可信度，使开发人员能够根据置信度合理决策是否使用这些摘要。

## 研究动机

- 代码摘要的重要性：良好的代码摘要有助于维护者理解代码，但高质量的摘要通常需要大量人工投入。
- 现有方法的不足：
    - 评价 LLM 生成摘要的方法主要包括 BERTScore 和 BLEU 等，但这些方法依赖于“黄金标准”（gold standard）的人工摘要，现实中往往不可得。
    - LLM 生成摘要的置信度往往不可靠，即使质量不佳的摘要可能仍然有高置信度。
- 校准（Calibration）的价值：
    - 校准是一种衡量预测置信度是否与实际正确率一致的方法。
    - 通过校准，使 LLM 在生成摘要时提供更可信的置信度分数，以指导开发人员是否采纳摘要。

## 研究目标

论文围绕三个核心研究问题：

1. LLM 生成摘要的置信度是否能直接反映摘要质量？
    - 现有 LLM 计算置信度的方法是否与摘要的实际正确性一致？
2. 置信度校准（Rescaling）是否能改善 LLM 置信度的可靠性？
    - 通过 Platt Rescaling 方法调整置信度，以提高与摘要质量的一致性。
3. 摘要中较早生成的 token（词元）是否比后续 token 更可靠？
    - LLM 生成的摘要越往后，其置信度是否会过度膨胀？

## 关键概念

**代码摘要（Code Summarization）**

代码摘要是一种自动软件文档生成任务，目标是从代码中提取简明、相关的信息，以便开发人员理解。

现有 LLM（如 GPT-3.5-Turbo、CodeLlama-70B、DeepSeek-Coder-33B）能够自动生成代码摘要，但质量参差不齐。

**置信度校准（Confidence Calibration）**

置信度校准是使模型预测置信度与实际正确率匹配的过程。

例如，一个理想的模型，如果对某些摘要的置信度为 80%，那么这些摘要在现实中应当有 80% 的概率与人类编写的摘要相似。

**校准度量方法**

1. Brier Score（布里尔分数）
    - 衡量预测置信度与实际正确率之间的均方误差，越低越好。
    - 计算公式：$Br = \frac{1}{N} \sum_{i = 1}{N} (p_{i} - a{i})^{2}$，其中 $p_{i}$ 是预测置信度，$o_{i}$ 是实际正确率（1 表示正确，0 表示错误）。

2. Expected Calibration Error（ECE，期望校准误差）
    - 衡量不同置信度区间（bins）内的平均误差。
    - 计算公式：$ECE = \sum_{i = 1}^{m} \frac{|B_{i}|}{|T|} |acc(B_{i}) - conf(B_{i})|$

3. Platt Scaling（普拉特缩放）
    - 一种用于调整置信度分布的后处理方法，使置信度分数更符合实际正确率。

## 研究方法

1. 使用 LLM 生成代码摘要
    - 选择三种 LLM：
        - GPT-3.5-Turbo
        - CodeLlama-70B
        - DeepSeek-Coder-33B
    - 采用先进的提示工程技术：
        - BM25 检索增强 Few-shot（Retrieval-Augmented Few-shot）：利用 BM25 选择相关示例，提高摘要质量。
        - 自动语义增强（ASAP, Automatic Semantic Augmentation of Prompt）：通过静态分析增强代码摘要，改进 LLM 生成摘要的能力。
2. 计算 LLM 置信度
    - 采用**几何均值（Geometric Mean）**聚合每个 token 的置信度，得到摘要整体置信度。
3. 评估摘要质量
    - 使用 BERTScore 计算摘要与人工摘要的相似度。
    - 设定不同的阈值（Thresholds），将摘要分类为“高质量”或“低质量”：
        - 高精度阈值（0.89）：保证摘要高度接近人工摘要。
        - 高召回阈值（0.80）：尽可能保留所有可能的高质量摘要。
        - 最优 F1 阈值（0.49）：在精度与召回率之间取得平衡。
4. 置信度校准
    - Platt Scaling 重新缩放 LLM 置信度，使其更符合实际情况。

## 实验结果

1. RQ1 结果：LLM 原始置信度不可靠
    - LLM 生成的摘要置信度未能有效反映摘要质量。
    - Brier Score 和 ECE 指标较高，表明 LLM 置信度严重偏差。
2. RQ2 结果：Platt Scaling 提高置信度可靠性
    - Platt Scaling 校准后，所有 LLM 置信度的 Brier Score 和 ECE 降低。
    - 校准后，CodeLlama-70B 在 Java 代码摘要上的 Skill Score 提高到 0.11。
3. RQ3 结果：摘要前半部分 token 置信度更可靠
    - 研究发现，摘要后续 token 置信度往往被 LLM 过度膨胀。
    - 仅使用摘要的前 7 个 token 计算置信度，可提高校准效果。

## 结论

现有 LLM 置信度不足以可靠地衡量代码摘要质量。

Platt Scaling 可有效提高 LLM 置信度的可靠性，使置信度分数更具参考价值。

摘要中的前几个 token 对校准更有价值，后续 token 置信度往往存在膨胀现象。

在不同的使用场景下，开发者应根据校准后的置信度调整对 LLM 生成摘要的信任程度。
