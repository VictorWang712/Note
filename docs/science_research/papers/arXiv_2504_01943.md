---
comments: true
---

# [arXiv] OpenCodeReasoning: Advancing Data Distillation for Competitive Coding

???+ info

    - Author: Wasi Uddin Ahmad, Sean Narenthiran, Somshubra Majumdar, Aleksander Ficek, Siddhartha Jain, Jocelyn Huang, Vahid Noroozi, Boris Ginsburg
    - arXiv: [2503.01943](https://arxiv.org/abs/2503.01943)

<div class="card file-block" markdown="1">
<div class="file-icon"><img src="/Note/assets/images/icons/pdf.svg" style="height: 3em;"></div>
<div class="file-body">
<div class="file-title">论文</div>
<div class="file-meta">364 KB / 15 P / 2025-04-18</div>
</div>
<a class="down-button" target="_blank" href="/Note/assets/files/science_research/arXiv_2504_01943.pdf" markdown="1">:fontawesome-solid-download: 下载</a>
</div>

## 核心问题与贡献

### 研究背景

论文针对**编程竞赛中的代码生成任务**（Competitive Coding），提出了一种基于大规模数据蒸馏（Data Distillation）的监督微调（Supervised Fine-Tuning, SFT）方法。现有方法存在以下挑战：

1. **数据质量与规模限制**：高质量人工标注数据稀缺，传统方法依赖强化学习（Reinforcement Learning, RL）或小规模合成数据，难以覆盖复杂编程问题。
2. **泛化能力不足**：现有模型在长尾问题（如高难度编程题目）上表现不佳，且难以跨语言（如Python与C++）迁移。
3. **推理效率低下**：生成代码前的推理过程（如链式思考，Chain-of-Thought）需消耗大量计算资源，影响实际应用。

### 主要创新点

1. **OpenCodeReasoning数据集**：
      - 包含 **736,712 个Python样本**和 **355,792 个C++样本**，覆盖28,904个独特编程问题，是目前最大的代码推理数据集。
      - 通过 **DeepSeek-R1** 生成多样化解决方案，支持多语言与多难度级别。
2. **纯监督微调（SFT-only）性能突破**：
      - 仅通过SFT训练，Qwen2.5系列模型在 **LiveCodeBench** 和 **CodeContests** 基准上达到最先进水平（32B模型分别取得61.8%和24.6%的pass@1准确率），超越依赖RL的模型。
3. **数据过滤与多样性分析**：
      - 发现**执行过滤（Execution Filtering）**会降低模型性能，强调**指令多样性**的重要性。
      - 验证多语言数据（如C++）对特定任务（如IOI基准）的增益，但需优化融合策略。

## 方法论详述

### 核心概念体系

- **数据蒸馏（Data Distillation）**：通过教师模型（如DeepSeek-R1）生成合成数据，用于学生模型（如Qwen2.5）的监督微调。
- **链式推理（Chain-of-Thought Reasoning）**：模型生成代码前通过 `<think>` 标签输出逻辑推理步骤，提升可解释性。
- **执行过滤（Execution Filtering）**：基于单元测试验证生成代码的正确性，但实验表明其可能损害模型泛化能力。

### 数据集构建流程

1. **问题收集与去重**：
      - 整合TACO、APPS、CodeContests等公开数据集，通过余弦相似度（阈值0.7）和人工审核消除语义重复。
2. **代码生成**：
      - 使用DeepSeek-R1进行多语言生成（Python/C++），参数：温度0.6，top-p 0.95，最大输出长度16k tokens。
3. **后处理**：
      - 分离推理步骤与代码块，验证语法正确性（Tree Sitter解析器），过滤含代码的推理文本。

### 训练与推理配置

- **模型架构**：基于Qwen2.5系列（7B/14B/32B），使用AdamW优化器，学习率5e-5，余弦退火调度，BF16精度。
- **推理策略**：温度采样（0.6），最大生成长度30,720 tokens，通过vLLM加速。

## 实验设计分析

### 数据集配置

|数据集|问题数量|样本数量|预处理方式|
|:-:|:-:|:-:|:-:|
|LiveCodeBench|279|-|2408-2502时间段问题，64次推理平均|
|CodeContests|28,904|736k|单元测试验证，16次推理平均|
|IOI|-|356k|仅C++评测，8次运行取最高分|

### 评估指标

- **pass@1**：单次生成通过所有测试用例的比例。
- **推理效率**：生成代码前的平均推理步数（Token数量）。

## 结果对比与讨论

### 性能对比

|模型规模|LiveCodeBench (pass@1)|CodeContests (pass@1)|关键结论|
|:-:|:-:|:-:|:-:|
|OCR-Qwen-7B|51.3%|18.1%|超越OlympicCoder-7B 10.4%|
|OCR-Qwen-32B|61.8%|24.6%|接近DeepSeek-R1（65.6%）|

### 消融实验

1. **执行过滤影响**：
      - 使用错误解决方案训练（151k样本）的模型性能优于正确解决方案（52.3% vs 47.0%），因错误样本覆盖更多高难度问题。
2. **多语言支持**：
      - 加入C++数据后，IOI基准提升30分（145.5→175.5），但对Python任务无显著增益。

### 推理模式分析

- **模式分布**：正确解决方案中**自我评估（Self-Evaluation）**和**子目标生成（Subgoal Generation）**占比显著更高（p<0.05）。
- **熵值对比**：正确方案熵值1.26 vs 错误方案1.19，多样性策略提升准确性。

## 未来研究方向

1. **数据生成优化**：
      - 结合生成模型（如GANs）提升问题多样性，覆盖动态规划等复杂算法。
2. **多模态融合**：
      - 引入自然语言问题描述，降低对输入输出样例的信息依赖。
3. **模型轻量化**：
      - 探索知识蒸馏（Knowledge Distillation）压缩32B模型，适配边缘设备。
4. **抗循环推理**：
      - 设计终止机制防止模型陷入重复推理循环（如Token预算动态调整）。
